{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Poetry Generation.ipynb",
      "provenance": [],
      "mount_file_id": "1ieW-ZJGPQeW9ziGN5Pv35qI8rlmHqYHB",
      "authorship_tag": "ABX9TyNovb7vLG3FarhbH1yheCYr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aju22/FrostLSTM-Remembering-Robert-Frost/blob/main/Poetry_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "hyzVVzo0qA8V"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Enable GPU"
      ],
      "metadata": {
        "id": "b-n0DdoKKodZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-gaQdofKqh2",
        "outputId": "3eea46ca-66de-44bf-88f1-9c7ee907c703"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameters"
      ],
      "metadata": {
        "id": "zlQWJUb4K2PP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_VOCAB_SIZE = 3000\n",
        "MAX_SEQUENCE_LENGTH = 100\n",
        "EMBEDDING_DIM = 50\n",
        "VALIDATION_SPLIT = 0.2\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 2000\n",
        "LATENT_DIM = 50"
      ],
      "metadata": {
        "id": "IpuIwt11q06h"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"drive/MyDrive/Poetry_Generation/Robert Frost.txt\"       \n",
        "word2vec_dir = \"drive/MyDrive/Poetry_Generation/glove.6B.50d.txt\"\n",
        "model_save_dir = \"/content/drive/MyDrive/Poetry_Generation/MODEL_CKPT.h5\""
      ],
      "metadata": {
        "id": "4IA7MNM8j48A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading Data"
      ],
      "metadata": {
        "id": "YCe9H-SLrP_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_texts = []\n",
        "target_texts = []\n",
        "\n",
        "for line in open(data_dir):\n",
        "  line = line.rstrip()\n",
        "  if not line:\n",
        "    continue\n",
        "\n",
        "  input_line = '<sos> ' + line\n",
        "  target_line = line + ' <eos>'\n",
        "\n",
        "\n",
        "  input_texts.append(input_line)      # <sos>  The    apple   fell  far   from  the    tree\n",
        "  target_texts.append(target_line)    #  The   apple  fell    far   from  the   tree   <eos>"
      ],
      "metadata": {
        "id": "Wn8au3XerGY5"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_lines = input_texts + target_texts"
      ],
      "metadata": {
        "id": "EgXk38KgrzP8"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "xzNQVkdLEOCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "euMSFqU-suWO"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words = MAX_VOCAB_SIZE, filters='''!\"#$%&()*'+,-./:;=?@[\\\\]^_`{|}~\\t''')\n",
        "tokenizer.fit_on_texts(all_lines)\n",
        "input_sequences = tokenizer.texts_to_sequences(input_texts)\n",
        "target_sequences = tokenizer.texts_to_sequences(target_texts)"
      ],
      "metadata": {
        "id": "tD8wVzM9s08J"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx = tokenizer.word_index\n",
        "print(f\"Unique Tokens : {len(word2idx)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5dThBvhvcKI",
        "outputId": "f46062a2-1a5d-484a-a764-37fac40842a8"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique Tokens : 2129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx2word = {v:k for k, v in word2idx.items()}"
      ],
      "metadata": {
        "id": "k74qFM_APF3s"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_length_of_data = max([len(s) for s in input_sequences])\n",
        "max_seq_length = min(max_sequence_length_of_data, MAX_SEQUENCE_LENGTH)\n",
        "print(f\"Max Length of Sequence : {max_seq_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyp3tFitt8tq",
        "outputId": "e37c45e7-6f23-4e7f-f8d7-cf4fbfb6d799"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Length of Sequence : 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "LRtpKpjIvYfS"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = pad_sequences(input_sequences, maxlen = max_seq_length, padding='post')\n",
        "target_sequences = pad_sequences(target_sequences, maxlen = max_seq_length, padding='post')"
      ],
      "metadata": {
        "id": "Y8p0YJcjwZm8"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pretrained Word2Vec"
      ],
      "metadata": {
        "id": "RKJ9yl3TETFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec = {}\n",
        "\n",
        "with open(word2vec_dir) as f:\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    vec = np.array(values[1:], dtype='float32')\n",
        "    word2vec[word] = vec"
      ],
      "metadata": {
        "id": "AqU1rTWnwsxR"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_words = min(MAX_VOCAB_SIZE, len(word2idx) + 1)\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))"
      ],
      "metadata": {
        "id": "-DUDTA3NDyaW"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word, i in word2idx.items():\n",
        "  if i < MAX_VOCAB_SIZE:\n",
        "    embedding_vector = word2vec.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "4XylX7VWElpo"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# One-Hot Encoding Targets"
      ],
      "metadata": {
        "id": "OiWXHzzGFMAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_targets = np.zeros((len(input_sequences), max_seq_length, num_words))"
      ],
      "metadata": {
        "id": "smfuMgP7FJKG"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, target_sequences in enumerate(target_sequences):\n",
        "  for t, word in enumerate(target_sequences):\n",
        "    if word > 0:\n",
        "      one_hot_targets[i, t, word] = 1"
      ],
      "metadata": {
        "id": "by1tG62tFnum"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the Model"
      ],
      "metadata": {
        "id": "aVsfI-mlGEL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Embedding, Input, LSTM "
      ],
      "metadata": {
        "id": "2zNcwWR_GD0O"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = Embedding(\n",
        "    num_words,\n",
        "    EMBEDDING_DIM,\n",
        "    weights = [embedding_matrix]\n",
        ")"
      ],
      "metadata": {
        "id": "2q1wOJe_GAmV"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = Input(shape = (max_seq_length, ))\n",
        "initial_h = Input(shape = (LATENT_DIM, ))\n",
        "initial_c = Input(shape = (LATENT_DIM, ))\n",
        "\n",
        "x = embedding_layer(input_layer)\n",
        "\n",
        "lstm = LSTM(LATENT_DIM, return_sequences=True, return_state=True)\n",
        "x, _, _ = lstm(x, initial_state = [initial_h, initial_c])\n",
        "\n",
        "dense = Dense(num_words, activation='softmax')\n",
        "output = dense(x)"
      ],
      "metadata": {
        "id": "KwZLOx3KGycg"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device(device_name):\n",
        "  model = Model([input_layer, initial_h, initial_c], output)\n",
        "\n",
        "  model.compile(\n",
        "    loss = 'categorical_crossentropy',\n",
        "    optimizer = 'adam',\n",
        "    metrics = ['accuracy']\n",
        "  )"
      ],
      "metadata": {
        "id": "Uh54F2tLIPsK"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(model_save_dir, save_best_only=True)\n",
        "]"
      ],
      "metadata": {
        "id": "BFyXIlkS3Da6"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "init = np.zeros((len(input_sequences), LATENT_DIM))\n",
        "\n",
        "with tf.device(device_name):\n",
        "  model.fit([input_sequences, init, init],\n",
        "          one_hot_targets,\n",
        "          batch_size = BATCH_SIZE,\n",
        "          epochs = EPOCHS,\n",
        "          validation_split = VALIDATION_SPLIT,\n",
        "          callbacks = callbacks)"
      ],
      "metadata": {
        "id": "cu0FgAacI2f2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the Model"
      ],
      "metadata": {
        "id": "A7MIB1TaNdPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model(\n",
        "    \"/content/drive/MyDrive/Poetry_Generation/MODEL_CKPT.h5\", custom_objects=None, compile=True, options=None\n",
        ")"
      ],
      "metadata": {
        "id": "GvrdRQkLLHdh"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4_RqizbM8Gs",
        "outputId": "afbffb98-f031-43e8-9489-53a43351fee9"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.engine.input_layer.InputLayer at 0x7f3cbe5f5f90>,\n",
              " <keras.layers.embeddings.Embedding at 0x7f3cc24477d0>,\n",
              " <keras.engine.input_layer.InputLayer at 0x7f3cbe5f55d0>,\n",
              " <keras.engine.input_layer.InputLayer at 0x7f3cbe61d790>,\n",
              " <keras.layers.recurrent_v2.LSTM at 0x7f3cc2496950>,\n",
              " <keras.layers.core.dense.Dense at 0x7f3cbc1c8350>]"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = model.layers[4]\n",
        "dense = model.layers[5]"
      ],
      "metadata": {
        "id": "1xQttEk-NDGO"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sampling Model"
      ],
      "metadata": {
        "id": "9Nmeiy3VMSfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input2 = Input(shape = (1, ))\n",
        "x = embedding_layer(input2)\n",
        "x, h, c = lstm(x, initial_state = [initial_h, initial_c])\n",
        "output2 = dense(x)"
      ],
      "metadata": {
        "id": "_5gkOzzMMEgu"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampling_model = Model([input2, initial_h, initial_c], [output2, h, c])"
      ],
      "metadata": {
        "id": "kxxLaXyqMqRC"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_line():\n",
        "\n",
        "  np_input = np.array([[word2idx['<sos>']]])\n",
        "  h = np.zeros((1, LATENT_DIM))\n",
        "  c = np.zeros((1, LATENT_DIM))\n",
        "\n",
        "  eos = word2idx['<eos>']\n",
        "\n",
        "  output_sentence = []\n",
        "\n",
        "  for _ in range(max_seq_length):\n",
        "    o, h, c = sampling_model.predict([np_input, h ,c])\n",
        "\n",
        "    probs = o[0,0]\n",
        "    if np.argmax(probs) == 0:\n",
        "      print(\"Null-Warning\")\n",
        "\n",
        "    probs[0] = 0\n",
        "    probs /= probs.sum()\n",
        "\n",
        "    idx = np.random.choice(len(probs), p = probs)\n",
        "    if idx == eos:\n",
        "      break\n",
        "\n",
        "    output_sentence.append(idx2word.get(idx, f\"<WARNING at {idx}>\"))\n",
        "\n",
        "    np_input[0,0] = idx\n",
        "\n",
        "  return ' '.join(output_sentence)   "
      ],
      "metadata": {
        "id": "tWNQ1IE2M3pF"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "POEM_LENGTH = 10\n",
        "\n",
        "for _ in range(POEM_LENGTH):\n",
        "  print(sample_line())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXJaYsFsPXnY",
        "outputId": "19296f1a-b36e-40fc-c31b-bc7c52be21b8"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "you let make a present but drowned in important\n",
            "except always john he chanced\n",
            "wishing in virgin feet\n",
            "behind the door of day in the kitchen field fate\n",
            "but they left a horny handed kindness\n",
            "the way a man of the window toward chases lowes from picking however\n",
            "the breath of air was such her nights out of believe\n",
            "i listened till me you sleep\n",
            "and stamped and were mounted for us believe everybody m granny speaking\n",
            "one bearing it your going to bear safely\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bTbJgn7TPj3b"
      },
      "execution_count": 167,
      "outputs": []
    }
  ]
}